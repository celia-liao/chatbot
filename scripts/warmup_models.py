#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹é ç†±è…³æœ¬
åœ¨éƒ¨ç½²æ™‚é å…ˆè¼‰å…¥ AI æ¨¡å‹ï¼Œæ¸›å°‘èŠå¤©æ™‚çš„ç­‰å¾…æ™‚é–“
"""

import os
import sys
import time
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# æ·»åŠ  mybot ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'mybot'))

def warmup_ollama_model():
    """é ç†± Ollama æ¨¡å‹"""
    print("ğŸ”¥ é ç†± Ollama æ¨¡å‹...")
    
    try:
        import ollama
        from mybot.chatbot_ollama import chat_with_pet, build_system_prompt
        
        model_name = os.getenv('OLLAMA_MODEL', 'qwen:7b')
        print(f"ğŸ“¦ æ¨¡å‹åç¨±: {model_name}")
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
        try:
            models = ollama.list()
            model_exists = any(model['name'] == model_name for model in models['models'])
            
            if not model_exists:
                print(f"âŒ æ¨¡å‹ {model_name} ä¸å­˜åœ¨ï¼Œå˜—è©¦ä¸‹è¼‰...")
                ollama.pull(model_name)
                print(f"âœ… æ¨¡å‹ {model_name} ä¸‹è¼‰å®Œæˆ")
            else:
                print(f"âœ… æ¨¡å‹ {model_name} å·²å­˜åœ¨")
                
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•æª¢æŸ¥æ¨¡å‹åˆ—è¡¨: {e}")
        
        # é ç†±æ¨¡å‹ - ç™¼é€ä¸€å€‹ç°¡å–®çš„è«‹æ±‚
        print("ğŸš€ é–‹å§‹é ç†±æ¨¡å‹...")
        start_time = time.time()
        
        system_prompt = "ä½ æ˜¯ä¸€éš»å¯æ„›çš„ç‹—ç‹—ï¼Œç”¨ç°¡å–®çš„è©±å›è¦†ã€‚"
        test_input = "ä½ å¥½"
        
        response = chat_with_pet(
            system_prompt=system_prompt,
            user_input=test_input,
            model=model_name
        )
        
        end_time = time.time()
        warmup_time = end_time - start_time
        
        print(f"âœ… Ollama æ¨¡å‹é ç†±å®Œæˆ")
        print(f"â±ï¸ é ç†±æ™‚é–“: {warmup_time:.2f} ç§’")
        print(f"ğŸ¤– æ¸¬è©¦å›è¦†: {response[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ollama æ¨¡å‹é ç†±å¤±æ•—: {e}")
        return False

def warmup_api_model():
    """é ç†± API æ¨¡å‹"""
    print("ğŸ”¥ é ç†± API æ¨¡å‹...")
    
    try:
        from mybot.chatbot_api import chat_with_pet_api
        
        model_name = os.getenv('QWEN_MODEL', 'qwen-flash')
        api_key = os.getenv('QWEN_API_KEY')
        api_url = os.getenv('QWEN_API_URL', 'https://api.qwen.com/v1/chat/completions')
        
        print(f"ğŸ“¦ æ¨¡å‹åç¨±: {model_name}")
        print(f"ğŸŒ API URL: {api_url}")
        print(f"ğŸ”‘ API Key: {'å·²è¨­å®š' if api_key else 'âŒ æœªè¨­å®š'}")
        
        if not api_key:
            print("âŒ API Key æœªè¨­å®šï¼Œç„¡æ³•é ç†± API æ¨¡å‹")
            return False
        
        # é ç†± API - ç™¼é€ä¸€å€‹ç°¡å–®çš„è«‹æ±‚
        print("ğŸš€ é–‹å§‹é ç†± API æ¨¡å‹...")
        start_time = time.time()
        
        system_prompt = "ä½ æ˜¯ä¸€éš»å¯æ„›çš„ç‹—ç‹—ï¼Œç”¨ç°¡å–®çš„è©±å›è¦†ã€‚"
        test_input = "ä½ å¥½"
        
        response = chat_with_pet_api(
            system_prompt=system_prompt,
            user_input=test_input,
            model=model_name
        )
        
        end_time = time.time()
        warmup_time = end_time - start_time
        
        print(f"âœ… API æ¨¡å‹é ç†±å®Œæˆ")
        print(f"â±ï¸ é ç†±æ™‚é–“: {warmup_time:.2f} ç§’")
        print(f"ğŸ¤– æ¸¬è©¦å›è¦†: {response[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ API æ¨¡å‹é ç†±å¤±æ•—: {e}")
        return False

def check_ollama_service():
    """æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹"""
    print("ğŸ” æª¢æŸ¥ Ollama æœå‹™...")
    
    try:
        import ollama
        
        # å˜—è©¦åˆ—å‡ºæ¨¡å‹
        models = ollama.list()
        print(f"âœ… Ollama æœå‹™æ­£å¸¸ï¼Œå·²è¼‰å…¥ {len(models['models'])} å€‹æ¨¡å‹")
        
        for model in models['models']:
            print(f"   - {model['name']} ({model['size']})")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ollama æœå‹™ç•°å¸¸: {e}")
        return False

def check_api_connection():
    """æª¢æŸ¥ API é€£æ¥"""
    print("ğŸ” æª¢æŸ¥ API é€£æ¥...")
    
    try:
        import httpx
        
        api_url = os.getenv('QWEN_API_URL', 'https://api.qwen.com/v1/chat/completions')
        
        with httpx.Client(timeout=10) as client:
            response = client.get(api_url)
            print(f"âœ… API é€£æ¥æ­£å¸¸ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return True
            
    except Exception as e:
        print(f"âŒ API é€£æ¥ç•°å¸¸: {e}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹æ¨¡å‹é ç†±...")
    print("=" * 50)
    
    ai_mode = os.getenv('AI_MODE', 'ollama')
    print(f"ğŸ¤– AI æ¨¡å¼: {ai_mode}")
    
    success = False
    
    if ai_mode == 'api':
        print("\nğŸŒ ä½¿ç”¨ API æ¨¡å¼")
        
        # æª¢æŸ¥ API é€£æ¥
        if check_api_connection():
            # é ç†± API æ¨¡å‹
            success = warmup_api_model()
        else:
            print("âŒ API é€£æ¥å¤±æ•—ï¼Œç„¡æ³•é ç†±")
            
    else:
        print("\nğŸ  ä½¿ç”¨ Ollama æ¨¡å¼")
        
        # æª¢æŸ¥ Ollama æœå‹™
        if check_ollama_service():
            # é ç†± Ollama æ¨¡å‹
            success = warmup_ollama_model()
        else:
            print("âŒ Ollama æœå‹™ç•°å¸¸ï¼Œç„¡æ³•é ç†±")
    
    print("\n" + "=" * 50)
    if success:
        print("âœ… æ¨¡å‹é ç†±å®Œæˆï¼")
        print("ğŸ’¡ ç¾åœ¨èŠå¤©æ™‚ç­‰å¾…æ™‚é–“æœƒå¤§å¹…æ¸›å°‘")
    else:
        print("âŒ æ¨¡å‹é ç†±å¤±æ•—")
        print("ğŸ’¡ è«‹æª¢æŸ¥ AI æ¨¡å¼è¨­å®šå’Œç›¸é—œæœå‹™")
    
    return success

if __name__ == "__main__":
    main()
